{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_pictures(directory, ext='jpg|JPG|jpeg|bmp|png|ppm'):\n",
    "#     print(directory)\n",
    "    res = [os.path.join(root, f)\n",
    "            for root, _, files in os.walk(directory) for f in files\n",
    "            if re.match(r'([\\w]+\\.(?:' + ext + '))', f)]\n",
    "#     print(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_negative_images(all_images,image_names,num_neg_images):\n",
    "    random_numbers = np.arange(len(all_images))\n",
    "    np.random.shuffle(random_numbers)\n",
    "    if int(num_neg_images)>(len(all_images)-1):\n",
    "        num_neg_images = len(all_images)-1\n",
    "    neg_count = 0\n",
    "    negative_images = []\n",
    "    for random_number in list(random_numbers):\n",
    "        if all_images[random_number] not in image_names:\n",
    "            negative_images.append(all_images[random_number])\n",
    "            neg_count += 1\n",
    "            if neg_count>(int(num_neg_images)-1):\n",
    "                break\n",
    "    return negative_images\n",
    "\n",
    "def get_positive_images(image_name,image_names,num_pos_images):\n",
    "    random_numbers = np.arange(len(image_names))\n",
    "    np.random.shuffle(random_numbers)\n",
    "    if int(num_pos_images)>(len(image_names)-1):\n",
    "        num_pos_images = len(image_names)-1\n",
    "    pos_count = 0\n",
    "    positive_images = []\n",
    "    for random_number in list(random_numbers):\n",
    "        if image_names[random_number]!= image_name:\n",
    "            positive_images.append(image_names[random_number])\n",
    "            pos_count += 1 \n",
    "            if int(pos_count)>(int(num_pos_images)-1):\n",
    "                break\n",
    "    return positive_images\n",
    "\n",
    "def triplet_sampler(directory_path, output_path,num_neg_images,num_pos_images):\n",
    "    classes = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "    all_images = []\n",
    "#     print(classes)\n",
    "    for class_ in classes:\n",
    "#         print(class_)\n",
    "        all_images += (list_pictures(os.path.join(directory_path,class_)))\n",
    "#     print(all_images)\n",
    "    triplets = []\n",
    "    for class_ in classes:\n",
    "        image_names = list_pictures(os.path.join(directory_path,class_))\n",
    "        for image_name in image_names:\n",
    "            image_names_set = set(image_names)\n",
    "            query_image = image_name\n",
    "            positive_images = get_positive_images(image_name,image_names,num_pos_images)\n",
    "            for positive_image in positive_images:\n",
    "                negative_images = get_negative_images(all_images,set(image_names),num_neg_images)\n",
    "                for negative_image in negative_images:\n",
    "                    triplets.append(query_image+',')\n",
    "                    triplets.append(positive_image+',')\n",
    "                    triplets.append(negative_image+'\\n')\n",
    "            \n",
    "    f = open(os.path.join(output_path,\"triplets.txt\"),'w')\n",
    "    f.write(\"\".join(triplets))\n",
    "#     print(triplets)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_sampler(\".\\\\dataset\",\"./triplets\",10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 (None, None, None, 3)\n",
      "block1_conv1 (None, None, None, 64)\n",
      "block1_conv2 (None, None, None, 64)\n",
      "block1_pool (None, None, None, 64)\n",
      "block2_conv1 (None, None, None, 128)\n",
      "block2_conv2 (None, None, None, 128)\n",
      "block2_pool (None, None, None, 128)\n",
      "block3_conv1 (None, None, None, 256)\n",
      "block3_conv2 (None, None, None, 256)\n",
      "block3_conv3 (None, None, None, 256)\n",
      "block3_pool (None, None, None, 256)\n",
      "block4_conv1 (None, None, None, 512)\n",
      "block4_conv2 (None, None, None, 512)\n",
      "block4_conv3 (None, None, None, 512)\n",
      "block4_pool (None, None, None, 512)\n",
      "block5_conv1 (None, None, None, 512)\n",
      "block5_conv2 (None, None, None, 512)\n",
      "block5_conv3 (None, None, None, 512)\n",
      "block5_pool (None, None, None, 512)\n",
      "input_2 (None, 224, 224, 3)\n",
      "input_3 (None, 224, 224, 3)\n",
      "global_average_pooling2d_1 (None, 512)\n",
      "conv2d_1 (None, 14, 14, 96)\n",
      "conv2d_2 (None, 7, 7, 96)\n",
      "dense_1 (None, 4096)\n",
      "max_pooling2d_1 (None, 4, 4, 96)\n",
      "max_pooling2d_2 (None, 4, 4, 96)\n",
      "dropout_1 (None, 4096)\n",
      "flatten_1 (None, 1536)\n",
      "flatten_2 (None, 1536)\n",
      "dense_2 (None, 4096)\n",
      "lambda_2 (None, 1536)\n",
      "lambda_3 (None, 1536)\n",
      "dropout_2 (None, 4096)\n",
      "concatenate_1 (None, 3072)\n",
      "lambda_1 (None, 4096)\n",
      "concatenate_2 (None, 7168)\n",
      "dense_3 (None, 4096)\n",
      "lambda_4 (None, 4096)\n",
      "Found 67 images belonging to 5 classes.\n",
      "Epoch 1/25\n",
      " 45/629 [=>............................] - ETA: 9:02:43 - loss: 0.9908"
     ]
    }
   ],
   "source": [
    "from  __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from ImageDataGeneratorCustom import ImageDataGeneratorCustom\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "def convnet_model_():\n",
    "    vgg_model = VGG16(weights=None, include_top=False)\n",
    "    x = vgg_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = Lambda(lambda  x_: K.l2_normalize(x,axis=1))(x)\n",
    "    convnet_model = Model(inputs=vgg_model.input, outputs=x)\n",
    "    return convnet_model\n",
    "\n",
    "def deep_rank_model():\n",
    " \n",
    "    convnet_model = convnet_model_()\n",
    "    first_input = Input(shape=(224,224,3))\n",
    "    first_conv = Conv2D(96, kernel_size=(8, 8),strides=(16,16), padding='same')(first_input)\n",
    "    first_max = MaxPool2D(pool_size=(3,3),strides = (4,4),padding='same')(first_conv)\n",
    "    first_max = Flatten()(first_max)\n",
    "    first_max = Lambda(lambda  x: K.l2_normalize(x,axis=1))(first_max)\n",
    "\n",
    "    second_input = Input(shape=(224,224,3))\n",
    "    second_conv = Conv2D(96, kernel_size=(8, 8),strides=(32,32), padding='same')(second_input)\n",
    "    second_max = MaxPool2D(pool_size=(7,7),strides = (2,2),padding='same')(second_conv)\n",
    "    second_max = Flatten()(second_max)\n",
    "    second_max = Lambda(lambda  x: K.l2_normalize(x,axis=1))(second_max)\n",
    "\n",
    "    merge_one = concatenate([first_max, second_max])\n",
    "\n",
    "    merge_two = concatenate([merge_one, convnet_model.output])\n",
    "    emb = Dense(4096)(merge_two)\n",
    "    l2_norm_final = Lambda(lambda  x: K.l2_normalize(x,axis=1))(emb)\n",
    "\n",
    "    final_model = Model(inputs=[first_input, second_input, convnet_model.input], outputs=l2_norm_final)\n",
    "\n",
    "    return final_model\n",
    "\n",
    "\n",
    "deep_rank_model = deep_rank_model()\n",
    "\n",
    "for layer in deep_rank_model.layers:\n",
    "    print (layer.name, layer.output_shape)\n",
    "\n",
    "model_path = \"./deep_ranking\"\n",
    "\n",
    "class DataGenerator(object):\n",
    "    def __init__(self, params, target_size=(224, 224)):\n",
    "        self.params = params\n",
    "        self.target_size = target_size\n",
    "        self.idg = ImageDataGeneratorCustom(**params)\n",
    "\n",
    "    def get_train_generator(self, batch_size):\n",
    "        return self.idg.flow_from_directory(\".\\\\dataset\",\n",
    "                                            batch_size=batch_size,\n",
    "                                            target_size=self.target_size,shuffle=False,\n",
    "                                            triplet_path  ='./triplets/triplets.txt'\n",
    "                                           )\n",
    "\n",
    "    def get_test_generator(self, batch_size):\n",
    "        return self.idg.flow_from_directory(\".\\\\dataset\",\n",
    "                                            batch_size=batch_size,\n",
    "                                            target_size=self.target_size, shuffle=False,\n",
    "                                            triplet_path  ='./triplets/triplets.txt'\n",
    "                                        )\n",
    "\n",
    "\n",
    "\n",
    "dg = DataGenerator({\n",
    "    \"rescale\": 1. / 255,\n",
    "    \"horizontal_flip\": True,\n",
    "    \"vertical_flip\": True,\n",
    "    \"zoom_range\": 0.2,\n",
    "    \"shear_range\": 0.2,\n",
    "    \"rotation_range\": 30,\n",
    "\"fill_mode\": 'nearest' \n",
    "}, target_size=(224, 224))\n",
    "\n",
    "batch_size = 8 \n",
    "batch_size *= 3\n",
    "train_generator = dg.get_train_generator(batch_size)\n",
    "\n",
    "\n",
    "_EPSILON = K.epsilon()\n",
    "def _loss_tensor(y_true, y_pred):\n",
    "    y_pred = K.clip(y_pred, _EPSILON, 1.0-_EPSILON)\n",
    "    loss =  tf.convert_to_tensor(0,dtype=tf.float32)\n",
    "    g = tf.constant(1.0, shape=[1], dtype=tf.float32)\n",
    "    for i in range(0,batch_size,3):\n",
    "        try:\n",
    "            q_embedding = y_pred[i+0]\n",
    "            p_embedding =  y_pred[i+1]\n",
    "            n_embedding = y_pred[i+2]\n",
    "            D_q_p =  K.sqrt(K.sum((q_embedding - p_embedding)**2))\n",
    "            D_q_n = K.sqrt(K.sum((q_embedding - n_embedding)**2))\n",
    "            loss = (loss + g + D_q_p - D_q_n )            \n",
    "        except:\n",
    "            continue\n",
    "    loss = loss/(batch_size/3)\n",
    "    zero = tf.constant(0.0, shape=[1], dtype=tf.float32)\n",
    "    return tf.maximum(loss,zero)\n",
    "\n",
    "#deep_rank_model.load_weights('deepranking.h5')\n",
    "deep_rank_model.compile(loss=_loss_tensor, optimizer=SGD(lr=0.001, momentum=0.9, nesterov=True))\n",
    "\n",
    "\n",
    "train_steps_per_epoch = int((15099)/batch_size)\n",
    "train_epocs = 25\n",
    "deep_rank_model.fit_generator(train_generator,\n",
    "                        steps_per_epoch=train_steps_per_epoch,\n",
    "                        epochs=train_epocs\n",
    "                        )\n",
    "\n",
    "model_path = \"deepranking.h5\"\n",
    "deep_rank_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import re\n",
    "# from scipy import linalg\n",
    "# import scipy.ndimage as ndi\n",
    "# from six.moves import range\n",
    "# import os\n",
    "# import threading\n",
    "# import warnings\n",
    "# import multiprocessing.pool\n",
    "# from functools import partial\n",
    "\n",
    "# import keras.backend as K\n",
    "# from PIL import Image as pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ext='jpg|jpeg|bmp|png|ppm'\n",
    "# a = [os.path.join(root, f)\n",
    "#             for root, _, files in os.walk(\".\\\\data\") for f in files\n",
    "#             if re.match(r'([\\w]+\\.(?:' + ext + '))', f)]\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
